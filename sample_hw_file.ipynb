{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Test File"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### problem 1 \n",
        "write a function that adds two numbers together"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def add(x,y):\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Include test cases for add here\n",
        "\n",
        "#"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### problem 2\n",
        "write a function to compute the term-document matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import subprocess\n",
        "import csv\n",
        "import re\n",
        "import random\n",
        "import numpy as np\n",
        "import scipy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def create_term_document_matrix(line_tuples, document_names, vocab):\n",
        "    \"\"\"Returns a numpy array containing the term document matrix for the input lines.\n",
        "\n",
        "    Inputs:\n",
        "      line_tuples: A list of tuples, containing the name of the document and\n",
        "      a tokenized line from that document.\n",
        "      document_names: A list of the document names\n",
        "      vocab: A list of the tokens in the vocabulary\n",
        "\n",
        "    Let m = len(vocab) and n = len(document_names).\n",
        "\n",
        "    Returns:\n",
        "      td_matrix: A mxn numpy array where the number of rows is the number of words\n",
        "          and each column corresponds to a document. A_ij contains the\n",
        "          frequency with which word i occurs in document j.\n",
        "    \"\"\"\n",
        "\n",
        "    return None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### problem 3\n",
        "Use the following functions to obtain the 10 most similar words to \"juliet\" according to the term-document matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def read_in_shakespeare():\n",
        "    \"\"\"Reads in the Shakespeare dataset and processes it into a list of tuples.\n",
        "       Also reads in the vocab and play name lists from files.\n",
        "\n",
        "    Each tuple consists of\n",
        "    tuple[0]: The name of the play\n",
        "    tuple[1] A line from the play as a list of tokenized words.\n",
        "\n",
        "    Returns:\n",
        "      tuples: A list of tuples in the above format.\n",
        "      document_names: A list of the plays present in the corpus.\n",
        "      vocab: A list of all tokens in the vocabulary.\n",
        "    \"\"\"\n",
        "\n",
        "    tuples = []\n",
        "\n",
        "    with open(\"shakespeare_plays.csv\") as f:\n",
        "        csv_reader = csv.reader(f, delimiter=\";\")\n",
        "        for row in csv_reader:\n",
        "            play_name = row[1]\n",
        "            line = row[5]\n",
        "            line_tokens = re.sub(r\"[^a-zA-Z0-9\\s]\", \" \", line).split()\n",
        "            line_tokens = [token.lower() for token in line_tokens]\n",
        "\n",
        "            tuples.append((play_name, line_tokens))\n",
        "\n",
        "    with open(\"vocab.txt\") as f:\n",
        "        vocab = [line.strip() for line in f]\n",
        "\n",
        "    with open(\"play_names.txt\") as f:\n",
        "        document_names = [line.strip() for line in f]\n",
        "\n",
        "    return tuples, document_names, vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def compute_cosine_similarity(vector1, vector2):\n",
        "    \"\"\"Computes the cosine similarity of the two input vectors.\n",
        "\n",
        "    Inputs:\n",
        "      vector1: A nx1 numpy array\n",
        "      vector2: A nx1 numpy array\n",
        "\n",
        "    Returns:\n",
        "      A scalar similarity value.\n",
        "    \"\"\"\n",
        "    # Check for 0 vectors\n",
        "    if not np.any(vector1) or not np.any(vector2):\n",
        "        sim = 0\n",
        "\n",
        "    else:\n",
        "        sim = 1 - scipy.spatial.distance.cosine(vector1, vector2)\n",
        "\n",
        "    return sim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def rank_words(target_word_index, matrix):\n",
        "    \"\"\"Ranks the similarity of all of the words to the target word using compute_cosine_similarity.\n",
        "\n",
        "    Inputs:\n",
        "      target_word_index: The index of the word we want to compare all others against.\n",
        "      matrix: Numpy matrix where the ith row represents a vector embedding of the ith word.\n",
        "\n",
        "    Returns:\n",
        "      A length-n list of integer word indices, ordered by decreasing similarity to the\n",
        "      target word indexed by word_index\n",
        "      A length-n list of similarity scores, ordered by decreasing similarity to the\n",
        "      target word indexed by word_index\n",
        "    \"\"\"\n",
        "\n",
        "    # Your Code here\n",
        "\n",
        "    return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def topTenWords(word):\n",
        "    tuples, document_names, vocab = read_in_shakespeare()\n",
        "    td_matrix = create_term_document_matrix(tuples, document_names, vocab)\n",
        "    vocab_to_index = dict(zip(vocab, range(0, len(vocab))))\n",
        "    ranks, scores = rank_words(vocab_to_index[word], td_matrix)\n",
        "    for idx in range(0,10):\n",
        "        word_id = ranks[idx]\n",
        "        print(\"%d: %s; %s\" %(idx+1, vocab[word_id], scores[idx]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "ename": "<class 'FileNotFoundError'>",
          "evalue": "[Errno 44] No such file or directory: 'shakespeare_plays.csv'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtopTenWords\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[0;32mIn[6], line 2\u001b[0m, in \u001b[0;36mtopTenWords\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtopTenWords\u001b[39m():\n\u001b[0;32m----> 2\u001b[0m     tuples, document_names, vocab \u001b[38;5;241m=\u001b[39m \u001b[43mread_in_shakespeare\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     vocab_to_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(vocab, \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(vocab))))\n\u001b[1;32m      5\u001b[0m     ranks, scores \u001b[38;5;241m=\u001b[39m rank_words(vocab_to_index[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjuliet\u001b[39m\u001b[38;5;124m\"\u001b[39m], td_matrix)\n",
            "Cell \u001b[0;32mIn[2], line 17\u001b[0m, in \u001b[0;36mread_in_shakespeare\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Reads in the Shakespeare dataset and processes it into a list of tuples.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m   Also reads in the vocab and play name lists from files.\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;124;03m  vocab: A list of all tokens in the vocabulary.\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     15\u001b[0m tuples \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshakespeare_plays.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     18\u001b[0m     csv_reader \u001b[38;5;241m=\u001b[39m csv\u001b[38;5;241m.\u001b[39mreader(f, delimiter\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m;\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m csv_reader:\n",
            "File \u001b[0;32m/lib/python3.11/site-packages/IPython/core/interactiveshell.py:286\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    283\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    284\u001b[0m     )\n\u001b[0;32m--> 286\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 44] No such file or directory: 'shakespeare_plays.csv'"
          ]
        }
      ],
      "source": [
        "topTenWords(\"juliet\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### problem 4\n",
        "Generate 100 random data points along 3 dimensions using np.random.randn  \n",
        "plot it using plot_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def plot_data(x, y, scale):\n",
        "    \n",
        "    fig, ax = plt.subplots()\n",
        "\n",
        "    # Map each onto a scatterplot we'll create with Matplotlib\n",
        "    ax.scatter(x=x, y=y, c=scale, s=np.abs(scale)*500)\n",
        "    ax.set(title=\"Plot 1\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def problem_4():\n",
        "    pass\n",
        "\n",
        "problem_4()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
